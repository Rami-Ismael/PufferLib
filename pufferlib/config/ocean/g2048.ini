[base]
package = ocean
env_name = puffer_g2048
policy_name = Policy
rnn_name = Recurrent

[policy]
hidden_size = 128

[rnn]
input_size = 128
hidden_size = 128

[vec]
num_envs = 4

[env]
num_envs = 4096

[train]
total_timesteps = 3_000_000_000
anneal_lr = True
batch_size = auto
bptt_horizon = 64
minibatch_size = 65536

adam_beta1 = 0.99
adam_beta2 = 0.96
adam_eps = 1.0e-10
clip_coef = 0.1
ent_coef = 0.02
gae_lambda = 0.6
gamma = 0.985
learning_rate = 0.003
max_grad_norm = 1.0
prio_alpha = 0.99
prio_beta0 = 0.40
vf_clip_coef = 0.1
vf_coef = 2.0
vtrace_c_clip = 4.3
vtrace_rho_clip = 1.6


[sweep]
metric = score
goal = maximize

[sweep.train.gae_lambda]
distribution = logit_normal
min = 0.01
mean = 0.6
max = 0.995
scale = auto