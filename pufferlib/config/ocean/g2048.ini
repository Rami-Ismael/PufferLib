[base]
package = ocean
env_name = puffer_g2048
policy_name = Policy
rnn_name = Recurrent

[policy]
hidden_size = 256

[rnn]
input_size = 256
hidden_size = 256

[vec]
num_envs = 4

[env]
num_envs = 4096

[train]
# https://wandb.ai/kywch/pufferlib/runs/n8xml0u9?nw=nwuserkywch
total_timesteps = 3_000_000_000
anneal_lr = True
batch_size = auto
bptt_horizon = 64
minibatch_size = 65536

adam_beta1 = 0.99
adam_beta2 = 0.96
adam_eps = 1.0e-10
clip_coef = 0.1
ent_coef = 0.02
gae_lambda = 0.6
gamma = 0.985
learning_rate = 0.001
max_grad_norm = 1.0
prio_alpha = 0.99
prio_beta0 = 0.40
vf_clip_coef = 0.1
vf_coef = 2.0
vtrace_c_clip = 4.3
vtrace_rho_clip = 1.6


[sweep]
metric = score
goal = maximize

[sweep.train.total_timesteps]
distribution = log_normal
min = 3e8
max = 1e10
mean = 1e9
scale = time

[sweep.train.learning_rate]
distribution = log_normal
min = 0.00001
mean = 0.001
max = 0.1
scale = 0.5

[sweep.train.gae_lambda]
distribution = logit_normal
min = 0.01
mean = 0.6
max = 0.995
scale = auto